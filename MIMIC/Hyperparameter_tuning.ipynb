{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-30T12:35:35.252342Z",
     "start_time": "2024-05-30T12:35:34.765043Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Get imputed data\n",
    "mimic_complete = pd.read_csv(\"./impute_mimic.csv\")\n",
    "mimic_complete['mort_28'].replace([False, True],[0, 1], inplace=True)"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T12:35:35.268332Z",
     "start_time": "2024-05-30T12:35:35.255309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create variables to store outcome Y, treatment T, and features X\n",
    "y = \"mort_28\"\n",
    "T = \"peep_regime\"\n",
    "X = [\"age\", \"sex\", \"weight\", \"height\", \"pf_ratio\", \"po2\", \"pco2\", \"ph\", \"driving_pressure\", \"lung_compliance\", \"map\", \"bilirubin\", \"creatinine\", \"platelets\", \"urea\", \"fio2\", \"hco3\", \"heart_rate\", \"minute_volume\", \"peep\", \"plateau_pressure\", \"respiratory_rate\", \"syst_blood_pressure\", \"diastolic_blood_pressure\"]"
   ],
   "id": "4a68b7148138542e",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T12:35:36.087264Z",
     "start_time": "2024-05-30T12:35:35.270308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "\n",
    "\n",
    "def hyperparameter_tuning_perform(mimic_complete, X, T):\n",
    "    # Train and test set\n",
    "    train, test = train_test_split(mimic_complete, test_size=0.3, random_state=None)\n",
    "    scaler = StandardScaler()\n",
    "    train[X] = scaler.fit_transform(train[X])\n",
    "    test[X] = scaler.transform(test[X])\n",
    "\n",
    "    # Define hyperparameter grids\n",
    "    logistic_param_grid = {\n",
    "        'C': [0.01, 0.1, 1, 10, 100],\n",
    "        'solver': ['lbfgs', 'saga'],\n",
    "        'max_iter': [100, 200, 300, 400, 500]}\n",
    "    rf_param_grid = {\n",
    "        'n_estimators': [50, 100, 200, 300],\n",
    "        'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "        'min_samples_leaf': [1, 2, 4, 6, 8]\n",
    "    }\n",
    "    dt_param_grid = {\n",
    "        'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "        'min_samples_leaf': [1, 2, 4, 6, 8]\n",
    "    }\n",
    "\n",
    "    # Hyperparameter tuning logistic regression\n",
    "    logistic_search = RandomizedSearchCV(LogisticRegression(random_state=123),\n",
    "                                         logistic_param_grid,\n",
    "                                         n_iter=25,\n",
    "                                         random_state=123,\n",
    "                                         n_jobs=-1,\n",
    "                                         cv=3,\n",
    "                                         scoring='accuracy'\n",
    "                                         )\n",
    "    logistic_search.fit(train[X], train[T])\n",
    "    propensity_logistic = logistic_search.best_estimator_\n",
    "    best_logistic_params = logistic_search.best_params_\n",
    "    best_logistic_accuracy = logistic_search.best_score_\n",
    "\n",
    "    # Hyperparameter tuning random forest\n",
    "    rf_search = RandomizedSearchCV(RandomForestClassifier(random_state=123),\n",
    "                                   rf_param_grid,\n",
    "                                   n_iter=25,\n",
    "                                   random_state=123,\n",
    "                                   n_jobs=-1,\n",
    "                                   cv=3,\n",
    "                                   scoring='accuracy')\n",
    "    rf_search.fit(train[X], train[T])\n",
    "    propensity_rf = rf_search.best_estimator_\n",
    "    best_rf_params = rf_search.best_params_\n",
    "    best_rf_accuracy = rf_search.best_score_\n",
    "\n",
    "    # Hyperparameter tuning decision tree\n",
    "    dt_search = RandomizedSearchCV(DecisionTreeClassifier(random_state=123),\n",
    "                                   dt_param_grid,\n",
    "                                   n_iter=25,\n",
    "                                   random_state=123,\n",
    "                                   n_jobs=-1,\n",
    "                                   cv=3,\n",
    "                                   scoring='accuracy')\n",
    "    dt_search.fit(train[X], train[T])\n",
    "    propensity_decision_tree = dt_search.best_estimator_\n",
    "    best_dt_params = dt_search.best_params_\n",
    "    best_dt_accuracy = dt_search.best_score_\n",
    "\n",
    "    return best_logistic_params, best_rf_params, best_dt_params, best_logistic_accuracy, best_rf_accuracy, best_dt_accuracy"
   ],
   "id": "a1cc0d98547b268f",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T12:37:33.346994Z",
     "start_time": "2024-05-30T12:35:36.089240Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def hyperparameter_tuning_iterate(mimic_complete, X, T, num_experiments):\n",
    "    logistic_params_list = []\n",
    "    rf_params_list = []\n",
    "    dt_params_list = []\n",
    "    logistic_accuracy_list = []\n",
    "    rf_accuracy_list = []\n",
    "    dt_accuracy_list = []\n",
    "\n",
    "    for i in range(num_experiments):\n",
    "        logistic_params, rf_params, dt_params, logistic_accuracy, rf_accuracy, dt_accuracy = hyperparameter_tuning_perform(mimic_complete, X, T)\n",
    "        \n",
    "        logistic_params_list.append(logistic_params)\n",
    "        rf_params_list.append(rf_params)\n",
    "        dt_params_list.append(dt_params)\n",
    "        \n",
    "        logistic_accuracy_list.append(logistic_accuracy)\n",
    "        rf_accuracy_list.append(rf_accuracy)\n",
    "        dt_accuracy_list.append(dt_accuracy)\n",
    "\n",
    "    return logistic_params_list, rf_params_list, dt_params_list, logistic_accuracy_list, rf_accuracy_list, dt_accuracy_list\n",
    "\n",
    "# Hyperparameter tuning\n",
    "logistic_params_list, rf_params_list, dt_params_list, logistic_accuracy_list, rf_accuracy_list, dt_accuracy_list = hyperparameter_tuning_iterate(mimic_complete, X, T, 10)"
   ],
   "id": "ef735827f3f159a7",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T12:37:33.362997Z",
     "start_time": "2024-05-30T12:37:33.348962Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('Logistic regression:')\n",
    "for i in range(len(logistic_params_list)):\n",
    "    print(logistic_params_list[i], logistic_accuracy_list[i])"
   ],
   "id": "2b03fa2950adcbdb",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T12:37:33.379030Z",
     "start_time": "2024-05-30T12:37:33.364970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('Random forest:')\n",
    "for i in range(len(rf_params_list)):\n",
    "    print(rf_params_list[i], rf_accuracy_list[i])"
   ],
   "id": "af775f24b319a3a0",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T12:37:33.394576Z",
     "start_time": "2024-05-30T12:37:33.380550Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('Decision tree:')\n",
    "for i in range(len(dt_params_list)):\n",
    "    print(dt_params_list[i], dt_accuracy_list[i])"
   ],
   "id": "6bac81aad908ff08",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T12:39:12.279624Z",
     "start_time": "2024-05-30T12:39:12.254654Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train and test\n",
    "train, test = train_test_split(mimic_complete, test_size=0.3, random_state=None)\n",
    "scaler = StandardScaler()\n",
    "train[X] = scaler.fit_transform(train[X])\n",
    "test[X] = scaler.transform(test[X])"
   ],
   "id": "1edafd5f64583758",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Evaluate on test set",
   "id": "abe0524bc88969f2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T12:49:29.682805Z",
     "start_time": "2024-05-30T12:49:29.626772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cross-validation accuracy test set\n",
    "propensity_logistic = LogisticRegression(solver=\"lbfgs\", max_iter=100, C=0.1, random_state=123)\n",
    "propensity_logistic.fit(train[X], train[T])\n",
    "logistic_accuracy = propensity_logistic.score(test[X], test[T])\n",
    "print('Accuracy logistic model: ', logistic_accuracy)"
   ],
   "id": "16a6fd2ea1b357b1",
   "execution_count": 27,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T12:49:32.719706Z",
     "start_time": "2024-05-30T12:49:32.706681Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from matplotlib import pyplot as plt\n",
    "test['propensity_score'] = propensity_logistic.predict_proba(test[X])[:, 1]\n",
    "test['predicted_group'] = (test['propensity_score'] >= 0.5).astype(int)\n",
    "group_distribution = test['predicted_group'].value_counts()\n",
    "print(group_distribution)\n",
    "print('Percentage treated: ', 67/(1116+67) * 100)"
   ],
   "id": "2c189ca08f276a34",
   "execution_count": 28,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T12:49:34.686707Z",
     "start_time": "2024-05-30T12:49:32.913362Z"
    }
   },
   "cell_type": "code",
   "source": [
    " # Cross-validation accuracy test set\n",
    "propensity_rf = RandomForestClassifier(n_estimators=300, max_depth=20, min_samples_leaf=4, random_state=123)\n",
    "propensity_rf.fit(train[X], train[T])\n",
    "rf_accuracy = propensity_rf.score(test[X], test[T])\n",
    "print('Accuracy logistic model: ', rf_accuracy)"
   ],
   "id": "4273c7ee21c7d72f",
   "execution_count": 29,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T12:49:34.762708Z",
     "start_time": "2024-05-30T12:49:34.688705Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from matplotlib import pyplot as plt\n",
    "test['propensity_score'] = propensity_rf.predict_proba(test[X])[:, 1]\n",
    "test['predicted_group'] = (test['propensity_score'] >= 0.5).astype(int)\n",
    "group_distribution = test['predicted_group'].value_counts()\n",
    "print(group_distribution)\n",
    "print('Percentage treated: ', 59/(1124+59) * 100)"
   ],
   "id": "17c3a9bdfd0db4c5",
   "execution_count": 30,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T12:49:34.826740Z",
     "start_time": "2024-05-30T12:49:34.763708Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cross-validation accuracy test set\n",
    "propensity_dt = DecisionTreeClassifier(max_depth=10, min_samples_leaf=1, random_state=123)\n",
    "propensity_dt.fit(train[X], train[T])\n",
    "dt_accuracy = propensity_dt.score(test[X], test[T])\n",
    "print('Accuracy logistic model: ', dt_accuracy) "
   ],
   "id": "d5e0d0171bca5350",
   "execution_count": 31,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T12:49:34.842707Z",
     "start_time": "2024-05-30T12:49:34.829707Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from matplotlib import pyplot as plt\n",
    "test['propensity_score'] = propensity_dt.predict_proba(test[X])[:, 1]\n",
    "test['predicted_group'] = (test['propensity_score'] >= 0.5).astype(int)\n",
    "group_distribution = test['predicted_group'].value_counts()\n",
    "print(group_distribution)\n",
    "print('Percentage treated: ', 102/(1081+102) * 100)"
   ],
   "id": "5c31abc216f90c48",
   "execution_count": 32,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
