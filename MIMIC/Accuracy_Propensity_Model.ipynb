{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-17T13:07:49.599910Z",
     "start_time": "2024-06-17T13:07:49.584917Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T13:07:49.630724Z",
     "start_time": "2024-06-17T13:07:49.601909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get imputed data\n",
    "mimic_complete = pd.read_csv(\"./impute_mimic.csv\")\n",
    "mimic_complete['mort_28'].replace([False, True],[0, 1], inplace=True)"
   ],
   "id": "b603a38161cddb33",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T13:07:49.646159Z",
     "start_time": "2024-06-17T13:07:49.633269Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create variables to store outcome Y, treatment T, and features X\n",
    "y = \"mort_28\"\n",
    "T = \"peep_regime\"\n",
    "P = [\"age\", \"weight\", \"pf_ratio\", \"po2\", \"driving_pressure\", \"fio2\", \"hco3\", \"plateau_pressure\", \"respiratory_rate\"]"
   ],
   "id": "b9282a71aff3e494",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T13:07:49.662112Z",
     "start_time": "2024-06-17T13:07:49.650128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train, test = train_test_split(mimic_complete, test_size=0.3)\n",
    "train[P].shape"
   ],
   "id": "196083c719c5a8c8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2758, 9)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T13:08:08.706506Z",
     "start_time": "2024-06-17T13:07:49.664087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Get AUC-ROC, Precision, Recall, F1-score for different models (regression, rf, decision tree)\n",
    "auc_roc_log_list = []\n",
    "auc_roc_rf_list = []\n",
    "auc_roc_dt_list = []\n",
    "\n",
    "precision_log_list = []\n",
    "precision_rf_list = []\n",
    "precision_dt_list = []\n",
    "\n",
    "recall_log_list = []\n",
    "recall_rf_list = []\n",
    "recall_dt_list =[]\n",
    "\n",
    "f1_log_list = []\n",
    "f1_rf_list = []\n",
    "f1_dt_list = []\n",
    "\n",
    "for i in range(50):\n",
    "     train, test = train_test_split(mimic_complete, test_size=0.3)\n",
    "\n",
    "    # Normalizing Data\n",
    "     normalizer = MinMaxScaler()\n",
    "     train[P] = normalizer.fit_transform(train[P])\n",
    "     test[P] = normalizer.fit_transform(test[P])\n",
    "          \n",
    "     # Different propensity score models (already did hyperparameter tuning)\n",
    "     propensity_logistic = LogisticRegression(solver=\"lbfgs\", max_iter=200, C=1.0, random_state=123)\n",
    "     propensity_rf = RandomForestClassifier(n_estimators=50, max_depth=None, min_samples_leaf=2, random_state=123)\n",
    "     propensity_decision_tree = DecisionTreeClassifier(max_depth=10, min_samples_leaf=1, random_state=123)     \n",
    "     \n",
    "     propensity_logistic.fit(train[P], train[T])\n",
    "     propensity_rf.fit(train[P], train[T])\n",
    "     propensity_decision_tree.fit(train[P], train[T])\n",
    "     \n",
    "     # Predict probabilities\n",
    "     y_probs_logistic = propensity_logistic.predict_proba(test[P])[:, 1]\n",
    "     y_probs_rf = propensity_rf.predict_proba(test[P])[:, 1]\n",
    "     y_probs_dt = propensity_decision_tree.predict_proba(test[P])[:, 1]\n",
    "     y_test = test[T]\n",
    "     \n",
    "     # Accuracy\n",
    "     # AUC-ROC: higher value indicates better discrimination performance\n",
    "     auc_roc_logistic = roc_auc_score(y_test, y_probs_logistic)\n",
    "     auc_roc_rf = roc_auc_score(y_test, y_probs_rf)\n",
    "     auc_roc_dt = roc_auc_score(y_test, y_probs_dt)    \n",
    "     auc_roc_log_list.append(auc_roc_logistic)\n",
    "     auc_roc_rf_list.append(auc_roc_rf)\n",
    "     auc_roc_dt_list.append(auc_roc_dt)\n",
    "     \n",
    "     # Precision: Measures the proportion of true positive predictions among all positive predictions made by the model\n",
    "     precision_log = precision_score(y_test, (y_probs_logistic > 0.5))\n",
    "     precision_rf = precision_score(y_test, (y_probs_rf > 0.5))\n",
    "     precision_dt = precision_score(y_test, (y_probs_dt > 0.5))\n",
    "     precision_log_list.append(precision_log)\n",
    "     precision_rf_list.append(precision_rf)\n",
    "     precision_dt_list.append(precision_dt)\n",
    "     \n",
    "     # Recall: Measures the model's ability to capture all positive instances     \n",
    "     recall_log = recall_score(y_test, (y_probs_logistic > 0.5))\n",
    "     recall_rf = recall_score(y_test, (y_probs_rf > 0.5))\n",
    "     recall_dt = recall_score(y_test, (y_probs_dt > 0.5))\n",
    "     recall_log_list.append(recall_log)\n",
    "     recall_rf_list.append(recall_rf)\n",
    "     recall_dt_list.append(recall_dt)\n",
    "     \n",
    "     # F1-score: Provides balance between precision and recall and is useful when the class distribution is uneven (!)     \n",
    "     f1_log = f1_score(y_test, (y_probs_logistic > 0.5))\n",
    "     f1_rf = f1_score(y_test, (y_probs_rf > 0.5))\n",
    "     f1_dt = f1_score(y_test, (y_probs_dt > 0.5))\n",
    "     f1_log_list.append(f1_log)\n",
    "     f1_rf_list.append(f1_rf)\n",
    "     f1_dt_list.append(f1_dt)\n"
   ],
   "id": "9c4a2baa55ce502f",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T13:08:08.722563Z",
     "start_time": "2024-06-17T13:08:08.707505Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Performance of the Propensity Models\n",
    "print(f\"AUC-ROC logistic: {sum(auc_roc_log_list)/len(auc_roc_log_list):.4f}\")\n",
    "print(f\"AUC-ROC rf: {sum(auc_roc_rf_list)/len(auc_roc_rf_list) :.4f}\")\n",
    "print(f\"AUC-ROC dt: {sum(auc_roc_dt_list)/len(auc_roc_dt_list):.4f}\")\n",
    "\n",
    "print(f\"Precision-score logistic: {sum(precision_log_list)/len(precision_log_list):.4f}\")\n",
    "print(f\"Precision-score rf: {sum(precision_rf_list)/len(precision_rf_list) :.4f}\")\n",
    "print(f\"Precision-score dt: {sum(precision_dt_list)/len(precision_dt_list):.4f}\")\n",
    "\n",
    "print(f\"Recall-score logistic: {sum(recall_log_list)/len(recall_log_list):.4f}\")\n",
    "print(f\"Recall-score rf: {sum(recall_rf_list)/len(recall_rf_list) :.4f}\")\n",
    "print(f\"Recall-score dt: {sum(recall_dt_list)/len(recall_dt_list):.4f}\")\n",
    "\n",
    "print(f\"f1-score logistic: {sum(f1_log_list)/len(f1_log_list):.4f}\")\n",
    "print(f\"f1-score rf: {sum(f1_rf_list )/len(f1_rf_list ) :.4f}\")\n",
    "print(f\"f1-score dt: {sum(f1_dt_list)/len(f1_dt_list):.4f}\")"
   ],
   "id": "9467d53d88363c12",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC logistic: 0.8272\n",
      "AUC-ROC rf: 0.7210\n",
      "AUC-ROC dt: 0.5278\n",
      "Precision-score logistic: 0.4729\n",
      "Precision-score rf: 0.4374\n",
      "Precision-score dt: 0.1854\n",
      "Recall-score logistic: 0.4296\n",
      "Recall-score rf: 0.1944\n",
      "Recall-score dt: 0.3265\n",
      "f1-score logistic: 0.3894\n",
      "f1-score rf: 0.2148\n",
      "f1-score dt: 0.1908\n"
     ]
    }
   ],
   "execution_count": 20
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
