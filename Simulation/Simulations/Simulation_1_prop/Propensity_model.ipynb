{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-29T07:39:29.082334Z",
     "start_time": "2024-05-29T07:39:28.090795Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "from matplotlib import pyplot as plt\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T07:39:29.097420Z",
     "start_time": "2024-05-29T07:39:29.084336Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Simulation 1: The unbalanced case with a simple CATE\n",
    "# N = [300, 1000, 3000, 6000, 10000]\n",
    "N = 1000\n",
    "num_experiments = 10\n",
    "\n",
    "# Simulation setup\n",
    "e = lambda x: 0.1 # Important to note: the 'actual' propensity score is 10%\n",
    "d = 20\n",
    "beta = np.random.uniform(low=-5, high=5, size=d)\n",
    "mu0 = lambda x: np.dot(x, beta) + 5 * (x[0] > 0.5)\n",
    "mu1 = lambda x: mu0(x) + 8 * (x[1] > 0.1)"
   ],
   "id": "83224153b1a6941",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T07:39:34.141454Z",
     "start_time": "2024-05-29T07:39:29.098939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from Simulation.Perform_experiments_prop import propensity_model_simulation_data\n",
    "y_probs_logistic, y_probs_rf, y_probs_dt, y_test = propensity_model_simulation_data(N, e, d, mu0, mu1)"
   ],
   "id": "6be78d4ed644a46d",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T07:30:38.157399Z",
     "start_time": "2024-05-29T07:30:38.121399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Predicted Propensity Scores Logistic:\")\n",
    "print(y_probs_logistic)\n",
    "print(\"Predicted Propensity Scores RF:\")\n",
    "print(y_probs_rf)\n",
    "print(\"Predicted Propensity Scores DT:\")\n",
    "print(y_probs_dt)\n",
    "print(\"\\nActual Treatment Indicators:\")\n",
    "print(y_test)"
   ],
   "id": "666f13bcb43ee417",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T07:34:27.527700Z",
     "start_time": "2024-05-29T07:34:27.502679Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate accuracy of propensity score model\n",
    "def calculate_accuracy(y_probs, y_test, threshold=0.5):\n",
    "    # Convert propensity scores to binary treatment assignment using a threshold\n",
    "    y_pred = (y_probs >= threshold).astype(int)\n",
    "    print(y_pred, y_test)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = np.mean(y_pred == y_test)\n",
    "    \n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "# Calculate accuracy of propensity score model\n",
    "accuracy_log = calculate_accuracy(y_probs_logistic, y_test)\n",
    "accuracy_rf = calculate_accuracy(y_probs_rf, y_test)\n",
    "accuracy_dt = calculate_accuracy(y_probs_dt, y_test)\n",
    "# print(\"Accuracy using logistic regression:\", accuracy_log)\n",
    "# print(\"Accuracy using RF:\", accuracy_rf)\n",
    "# print(\"Accuracy using DT:\", accuracy_dt)"
   ],
   "id": "1f97acd8c9eabe46",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T11:45:19.501641Z",
     "start_time": "2024-05-28T11:45:19.283639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# \n",
    "# # Visualize the distribution of predicted propensity scores\n",
    "# plt.hist(y_probs, bins=20)\n",
    "# plt.xlabel('Predicted Propensity Score')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.title('Distribution of Predicted Propensity Scores')\n",
    "# plt.show()"
   ],
   "id": "53d69efc0606fae5",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T11:37:07.353653Z",
     "start_time": "2024-05-28T11:37:07.329668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score\n",
    "# \n",
    "# # Accuracy metrics\n",
    "# auc_roc = roc_auc_score(y_test, y_probs)\n",
    "# precision = precision_score(y_test, (y_probs > 0.5))\n",
    "# recall = recall_score(y_test, (y_probs > 0.5))\n",
    "# f1 = f1_score(y_test, (y_probs > 0.5))\n",
    "# \n",
    "# print(f\"AUC-ROC: {auc_roc:.4f}\")\n",
    "# print(f\"Precision: {precision:.4f}\")\n",
    "# print(f\"Recall: {recall:.4f}\")\n",
    "# print(f\"F1-Score: {f1:.4f}\")"
   ],
   "id": "8f23cc1abf603154",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "3495ec093846d28d",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
