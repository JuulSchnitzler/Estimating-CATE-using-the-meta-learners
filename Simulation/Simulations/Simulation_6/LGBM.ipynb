{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T21:00:21.115454Z",
     "start_time": "2024-05-22T21:00:21.103451Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import beta as beta_distribution\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "id": "2e5a937fcbe48c0d",
   "execution_count": 21,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T21:00:21.130464Z",
     "start_time": "2024-05-22T21:00:21.117453Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Generate feature vectors\n",
    "def generate_feature_vectors(N, d):\n",
    "    return np.random.uniform(0, 1, (N, d))\n",
    "\n",
    "# Propensity score function\n",
    "def propensity_score(x):\n",
    "    return 1 / 4 * (1 + beta_distribution.pdf(x[0], 2, 4))\n",
    "\n",
    "# Response functions\n",
    "mu0 = lambda x: 2 * x[0] - 1\n",
    "mu1 = mu0"
   ],
   "id": "9f2f8fae820406b",
   "execution_count": 22,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T21:00:21.162455Z",
     "start_time": "2024-05-22T21:00:21.133451Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from Simulation.X_learner import X_learner_lgbm, X_learner_linear, X_learner_rf, X_learner_svm, X_learner_nn\n",
    "from Simulation.T_learner import T_learner_lgbm, T_learner_linear, T_learner_rf, T_learner_svm, T_learner_nn\n",
    "from Simulation.S_learner import S_learner_lgbm, S_learner_linear, S_learner_rf, S_learner_svm, S_learner_nn\n",
    "\n",
    "\n",
    "# Generate potential outcomes\n",
    "def potential_outcomes(X, mu0, mu1):\n",
    "    Y0 = []\n",
    "    Y1 = []\n",
    "    for sample in X:\n",
    "        err_0 = np.random.normal(loc=0, scale=1)\n",
    "        err_1 = np.random.normal(loc=0, scale=1)\n",
    "        Yi_0 = mu0(sample) + err_0\n",
    "        Yi_1 = mu1(sample) + err_1\n",
    "        Y0.append(Yi_0)\n",
    "        Y1.append(Yi_1)\n",
    "    return Y0, Y1\n",
    "\n",
    "\n",
    "# Simulate data for a single experiment\n",
    "def generate_data(N, d, mu0, mu1):\n",
    "    X = generate_feature_vectors(N, d)\n",
    "    e = np.array([propensity_score(x) for x in X])\n",
    "    Y0, Y1 = potential_outcomes(X, mu0, mu1)\n",
    "    T = np.random.binomial(1, e, size=N)\n",
    "    Y = T * Y1 + (1 - T) * Y0\n",
    "    return X, T, Y0, Y1, Y\n",
    "\n",
    "def make_dataframe(X, T, Y0, Y1, Y):\n",
    "    df = pd.DataFrame(X)\n",
    "    df.columns = [f\"X{i}\" for i in range(1, X.shape[1] + 1)]\n",
    "    df['T'] = T\n",
    "    df['Y0'] = Y0\n",
    "    df['Y1'] = Y1\n",
    "    df['Y'] = Y\n",
    "    df['cate'] = df['Y1'] - df['Y0']\n",
    "    return df\n",
    "\n",
    "# Calculate the MSE\n",
    "def calculate_mse(test_df):\n",
    "    return mean_squared_error(test_df['cate'], test_df['pred_cate'])\n",
    "\n",
    "# Perform multiple experiments with different sample sizes\n",
    "def perform_experiments(N_list, d, mu0, mu1, model):\n",
    "    s_mse_list, t_mse_list, x_mse_list = [], [], []\n",
    "\n",
    "    for N in N_list:\n",
    "        X, T, Y0, Y1, Y = generate_data(N, d, mu0, mu1)\n",
    "        df_sim = make_dataframe(X, T, Y0, Y1, Y)\n",
    "        X_sim = [f\"X{i}\" for i in range(1, d + 1)]\n",
    "        train_sim, test_sim = train_test_split(df_sim, test_size=0.3, random_state=13)\n",
    "        \n",
    "        if model == \"LGBM\":\n",
    "            # Get CATE estimates (for S-, T- and X-learner)\n",
    "            s_cate_train, s_cate_test = S_learner_lgbm(train_sim, test_sim, X_sim, 'T', 'Y')\n",
    "            t_cate_train, t_cate_test = T_learner_lgbm(train_sim, test_sim, X_sim, 'T', 'Y')\n",
    "            x_cate_train, x_cate_test = X_learner_lgbm(train_sim, test_sim, X_sim, 'T', 'Y')\n",
    "\n",
    "        elif model == \"LinearRegression\":\n",
    "            # Get CATE estimates (for S-, T- and X-learner)\n",
    "            s_cate_train, s_cate_test = S_learner_linear(train_sim, test_sim, X_sim, 'T', 'Y')\n",
    "            t_cate_train, t_cate_test = T_learner_linear(train_sim, test_sim, X_sim, 'T', 'Y')\n",
    "            x_cate_train, x_cate_test = X_learner_linear(train_sim, test_sim, X_sim, 'T', 'Y')\n",
    "\n",
    "        elif model == \"RF\":\n",
    "            # Get CATE estimates (for S-, T- and X-learner)\n",
    "            s_cate_train, s_cate_test = S_learner_rf(train_sim, test_sim, X_sim, 'T', 'Y')\n",
    "            t_cate_train, t_cate_test = T_learner_rf(train_sim, test_sim, X_sim, 'T', 'Y')\n",
    "            x_cate_train, x_cate_test = X_learner_rf(train_sim, test_sim, X_sim, 'T', 'Y')\n",
    "\n",
    "        elif model == \"SVM\":\n",
    "            # Get CATE estimates (for S-, T- and X-learner)\n",
    "            s_cate_train, s_cate_test = S_learner_svm(train_sim, test_sim, X_sim, 'T', 'Y')\n",
    "            t_cate_train, t_cate_test = T_learner_svm(train_sim, test_sim, X_sim, 'T', 'Y')\n",
    "            x_cate_train, x_cate_test = X_learner_svm(train_sim, test_sim, X_sim, 'T', 'Y')\n",
    "\n",
    "        elif model == \"NN\":\n",
    "            # Get CATE estimates (for S-, T- and X-learner)\n",
    "            s_cate_train, s_cate_test = S_learner_nn(train_sim, test_sim, X_sim, 'T', 'Y')\n",
    "            t_cate_train, t_cate_test = T_learner_nn(train_sim, test_sim, X_sim, 'T', 'Y')\n",
    "            x_cate_train, x_cate_test = X_learner_nn(train_sim, test_sim, X_sim, 'T', 'Y')\n",
    "\n",
    "        else:\n",
    "            s_cate_train, s_cate_test = None, None\n",
    "            t_cate_train, t_cate_test = None, None\n",
    "            x_cate_train, x_cate_test = None, None\n",
    "        \n",
    "        # Calculate MSE\n",
    "        s_mse_list.append(calculate_mse(s_cate_test))\n",
    "        t_mse_list.append(calculate_mse(t_cate_test))\n",
    "        x_mse_list.append(calculate_mse(x_cate_test))\n",
    "\n",
    "    return s_mse_list, t_mse_list, x_mse_list\n",
    "\n",
    "def iterate_experiments(N_list, num_experiments, d, mu0, mu1, model):\n",
    "    s_mse_total, t_mse_total, x_mse_total = [], [], []\n",
    "\n",
    "    for _ in range(num_experiments):\n",
    "        s_mse, t_mse, x_mse = perform_experiments(N_list, d, mu0, mu1, model)\n",
    "        s_mse_total.append(s_mse)\n",
    "        t_mse_total.append(t_mse)\n",
    "        x_mse_total.append(x_mse)\n",
    "\n",
    "    return s_mse_total, t_mse_total, x_mse_total"
   ],
   "id": "49bb583a7da116e8",
   "execution_count": 23,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T21:00:21.178452Z",
     "start_time": "2024-05-22T21:00:21.165454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Simulation setup for the confounded case\n",
    "N_list = [300, 1000, 3000, 6000, 10000]\n",
    "num_experiments = 10\n",
    "d = 20"
   ],
   "id": "6fa4ff7950ad2c64",
   "execution_count": 24,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T21:03:01.113149Z",
     "start_time": "2024-05-22T21:00:21.181467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# LGBM Regressor as model\n",
    "model = \"LGBM\"\n",
    "s_mse_total, t_mse_total, x_mse_total= iterate_experiments(N_list, num_experiments, d, mu0, mu1, model)\n",
    "s_mse_lgbm = np.mean(s_mse_total, axis=0)\n",
    "t_mse_lgbm = np.mean(t_mse_total, axis=0)\n",
    "x_mse_lgbm = np.mean(x_mse_total, axis=0)"
   ],
   "id": "7c0468ed4ac4bab3",
   "execution_count": 25,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T21:03:01.252113Z",
     "start_time": "2024-05-22T21:03:01.114116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Plotting the average MSE for different num of samples\n",
    "plt.plot(N_list, s_mse_lgbm, marker='o', label='S-learner')\n",
    "plt.plot(N_list, t_mse_lgbm, marker='o', label='T-learner')\n",
    "plt.plot(N_list, x_mse_lgbm, marker='o', label='X-learner')\n",
    "plt.xlabel('Number of samples')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('Simulation 6: LGBM Regressor')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "42e8390e930e7537",
   "execution_count": 26,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T21:03:01.268147Z",
     "start_time": "2024-05-22T21:03:01.253115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"LGBM:\")\n",
    "print(\"S-learner: \")\n",
    "print(s_mse_lgbm)\n",
    "print(\"T-learner: \")\n",
    "print(t_mse_lgbm)\n",
    "print(\"X-learner: \")\n",
    "print(x_mse_lgbm)"
   ],
   "id": "9da13b1f06092c92",
   "execution_count": 27,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
